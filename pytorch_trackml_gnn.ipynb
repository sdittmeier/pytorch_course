{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data \n",
    "!mkdir graph_data\n",
    "!wget https://www.physi.uni-heidelberg.de/~dittmeier/pytorch/graph_data/graphs_pT2GeV.zip\n",
    "#wget https://www.physi.uni-heidelberg.de/~dittmeier/pytorch/graph_data/graphs_no_pTCut.zip # uncomment this line to download the data without pT cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip graphs_pT2GeV.zip -d graph_data\n",
    "#!unzip graphs_no_pTCut.zip -d graph_data   # uncomment this line to unzip the data without pT cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'graph_data/pTge2GeV'\n",
    "#data_dir = 'graph_data/nopTCut/' # uncomment this line to use the data without pT cut\n",
    "## for local use:\n",
    "data_dir = '/mnt/data0/Trackml_dataset_100_events/seb/metric_learning/pTge2GeV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu121\n"
     ]
    }
   ],
   "source": [
    "#install required packages\n",
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "#ensure that the PyTorch and the PyG are the same version\n",
    "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
    "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
    "\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(leta=[2718], module_index=[2718], lx=[2718], region=[2718], lphi=[2718], cell_val=[2718], weight=[2718], lz=[2718], phi=[2718], ly=[2718], x=[2718], hit_id=[2718], eta=[2718], geta=[2718], y=[7649], r=[2718], cell_count=[2718], z=[2718], gphi=[2718], track_edges=[2, 2477], particle_id=[2477], radius=[2477], pt=[2477], nhits=[2477], config=[2], event_id=[1], num_nodes=2718, batch=[2718], ptr=[2], edge_index=[2, 7649], truth_map=[2477])\n",
      "tensor(2718)\n",
      "7649\n",
      "tensor([[  34,   35,    0,  ..., 2710, 2711, 2715],\n",
      "        [   0,    0,   79,  ..., 2712, 2712, 2716]])\n",
      "tensor([ True, False, False,  ..., False, False,  True])\n",
      "tensor([   6,   12,   37,  ..., 7641, 7643, 7648])\n",
      "tensor([[   2,    5,   10,  ..., 2706, 2709, 2716],\n",
      "        [   7,    3,   11,  ..., 2707, 2711, 2715]])\n",
      "tensor([-109.3260,  -63.7417,  -42.1189,  ..., -307.3140, -307.0520,\n",
      "        -891.4610], dtype=torch.float64)\n",
      "tensor([109.3261,  87.2665,  68.3407,  ..., 798.6319, 798.4037, 973.5359],\n",
      "       dtype=torch.float64)\n",
      "tensor([ 3.1404, -2.3897, -2.2348,  ...,  1.9658,  1.9656,  2.7280],\n",
      "       dtype=torch.float64)\n",
      "tensor([-1502.0000, -1502.5000, -1498.0000,  ...,  2947.5000,  2944.5000,\n",
      "         2955.5000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "# Define the path to the PyG file\n",
    "file_path = f'{data_dir}/trainset/event000021000.pyg'\n",
    "\n",
    "# Load the PyG file\n",
    "data = torch.load(file_path)\n",
    "\n",
    "# Print the properties of the PyG file\n",
    "print(data)\n",
    "print(data.num_nodes)\n",
    "print(data.num_edges)\n",
    "print(data.edge_index)\n",
    "print(data.y)\n",
    "print(data.truth_map)\n",
    "print(data.track_edges)\n",
    "print(data.x)\n",
    "print(data.r)\n",
    "print(data.phi)\n",
    "print(data.z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import eval_utils\n",
    "from utils.version_utils import get_pyg_data_keys\n",
    "from utils import (\n",
    "    load_datafiles_in_dir,\n",
    "    run_data_tests,\n",
    "    handle_weighting,\n",
    "    handle_hard_cuts,\n",
    "    remap_from_mask,\n",
    "    handle_edge_features,\n",
    "    get_optimizers,\n",
    "    get_condition_lambda,\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Dataset\n",
    "\n",
    "class GraphDataset(Dataset):\n",
    "    \"\"\"\n",
    "    The custom default GNN dataset to load graphs off the disk\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dir,\n",
    "        data_name=None,\n",
    "        num_events=None,\n",
    "        stage=\"fit\",\n",
    "        hparams=None,\n",
    "        transform=None,\n",
    "        pre_transform=None,\n",
    "        pre_filter=None,\n",
    "        preprocess=True,\n",
    "    ):\n",
    "        if hparams is None:\n",
    "            hparams = {}\n",
    "        super().__init__(input_dir, transform, pre_transform, pre_filter)\n",
    "\n",
    "        self.input_dir = input_dir\n",
    "        self.data_name = data_name\n",
    "        self.hparams = hparams\n",
    "        self.num_events = num_events\n",
    "        self.stage = stage\n",
    "        self.preprocess = preprocess\n",
    "        self.transform = transform\n",
    "\n",
    "        self.input_paths = load_datafiles_in_dir(\n",
    "            self.input_dir, self.data_name, self.num_events\n",
    "        )\n",
    "        self.input_paths.sort()  # We sort here for reproducibility\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.input_paths)\n",
    "\n",
    "    def get(self, idx):\n",
    "        event_path = self.input_paths[idx]\n",
    "        event = torch.load(event_path, map_location=torch.device(\"cpu\"))\n",
    "        # convert DataBatch to Data instance because some transformations don't work on DataBatch\n",
    "        event = Data(**event.to_dict())\n",
    "        if not self.preprocess:\n",
    "            return event\n",
    "        event = self.preprocess_event(event)\n",
    "        # do pyg transformation if a torch_geometric.transforms instance is given\n",
    "        if self.transform is not None:\n",
    "            event = self.transform(event)\n",
    "\n",
    "        # return (event, event_path) if self.stage == \"predict\" else event\n",
    "        return event\n",
    "    \n",
    "    def preprocess_event(self, event):\n",
    "        \"\"\"\n",
    "        Process event before it is used in training and validation loops\n",
    "        \"\"\"\n",
    "        event = self.construct_weighting(event)\n",
    "        event = self.scale_features(event)\n",
    "        return event\n",
    "\n",
    "    def construct_weighting(self, event):\n",
    "        \"\"\"\n",
    "        Construct the weighting for the event\n",
    "        \"\"\"\n",
    "\n",
    "        assert event.y.shape[0] == event.edge_index.shape[1], (\n",
    "            f\"Input graph has {event.edge_index.shape[1]} edges, but\"\n",
    "            f\" {event.y.shape[0]} truth labels\"\n",
    "        )\n",
    "\n",
    "        if self.hparams is not None and \"weighting\" in self.hparams.keys():\n",
    "            assert isinstance(self.hparams[\"weighting\"], list) & isinstance(\n",
    "                self.hparams[\"weighting\"][0], dict\n",
    "            ), \"Weighting must be a list of dictionaries\"\n",
    "            event.weights = handle_weighting(event, self.hparams[\"weighting\"])\n",
    "        else:\n",
    "            event.weights = torch.ones_like(event.y, dtype=torch.float32)\n",
    "\n",
    "        return event\n",
    "\n",
    "\n",
    "    def scale_features(self, event):\n",
    "        \"\"\"\n",
    "        Handle feature scaling for the event\n",
    "        \"\"\"\n",
    "\n",
    "        if (\n",
    "            self.hparams is not None\n",
    "            and \"node_scales\" in self.hparams.keys()\n",
    "            and \"node_features\" in self.hparams.keys()\n",
    "        ):\n",
    "            assert isinstance(\n",
    "                self.hparams[\"node_scales\"], list\n",
    "            ), \"Feature scaling must be a list of ints or floats\"\n",
    "            for i, feature in enumerate(self.hparams[\"node_features\"]):\n",
    "                assert feature in get_pyg_data_keys(\n",
    "                    event\n",
    "                ), f\"Feature {feature} not found in event\"\n",
    "                event[feature] = event[feature] / self.hparams[\"node_scales\"][i]\n",
    "\n",
    "        return event\n",
    "\n",
    "    def apply_score_cut(self, event, score_cut):\n",
    "        \"\"\"\n",
    "        Apply a score cut to the event. This is used for the evaluation stage.\n",
    "        \"\"\"\n",
    "        passing_edges_mask = event.scores >= score_cut\n",
    "        num_edges = event.edge_index.shape[1]\n",
    "        for key in get_pyg_data_keys(event):\n",
    "            if (\n",
    "                isinstance(event[key], torch.Tensor)\n",
    "                and event[key].shape\n",
    "                and (\n",
    "                    event[key].shape[0] == num_edges\n",
    "                    or event[key].shape[-1] == num_edges\n",
    "                )\n",
    "            ):\n",
    "                event[key] = event[key][..., passing_edges_mask]\n",
    "\n",
    "        remap_from_mask(event, passing_edges_mask)\n",
    "        return event\n",
    "\n",
    "    def get_y_node(self, event):\n",
    "        y_node = torch.zeros(event.z.size(0))\n",
    "        y_node[event.track_edges.view(-1)] = 1\n",
    "        event.y_node = y_node\n",
    "        return event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in trainset: 80\n",
      "Number of samples in valset: 10\n",
      "Number of samples in testset: 10\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    \"node_features\": [\"r\",  \"phi\", \"z\"],\n",
    "    \"node_scales\": [1000, 3.14,  1000],\n",
    "    #\"weighting\": [], we can play with this\n",
    "}\n",
    "\n",
    "trainset = GraphDataset(f\"{data_dir}/trainset\", hparams=parameters)\n",
    "valset = GraphDataset(f\"{data_dir}/valset\", hparams=parameters)\n",
    "testset = GraphDataset(f\"{data_dir}/testset\", hparams=parameters)\n",
    "print(\"Number of samples in trainset:\", len(trainset))\n",
    "print(\"Number of samples in valset:\", len(valset))\n",
    "print(\"Number of samples in testset:\", len(testset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1093, 0.0873, 0.0683,  ..., 0.7986, 0.7984, 0.9735],\n",
      "       dtype=torch.float64)\n",
      "torch.Size([7649])\n",
      "torch.Size([7649])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "# Set batch size and number of workers\n",
    "batch_size = 1\n",
    "num_workers = 1\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "val_loader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "for test_event in train_loader:\n",
    "    print(test_event.r)\n",
    "    print(test_event.y.shape)\n",
    "    print(test_event.weights.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import MessagePassing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# https://pytorch-geometric.readthedocs.io/en/latest/tutorial/create_gnn.html\n",
    "\n",
    "class InteractionConv(MessagePassing):\n",
    "    def __init__(\n",
    "        self,\n",
    "        hidden_dim,\n",
    "        aggr=\"add\",\n",
    "        *,\n",
    "        aggr_kwargs={},\n",
    "        flow: str = \"source_to_target\",\n",
    "        node_dim: int = -2,\n",
    "        decomposed_layers: int = 1,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            aggr,\n",
    "            aggr_kwargs=aggr_kwargs,\n",
    "            flow=flow,\n",
    "            node_dim=node_dim,\n",
    "            decomposed_layers=decomposed_layers,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        self.node_network = nn.Sequential(\n",
    "            nn.Linear(2*hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.edge_network = nn.Sequential(\n",
    "            nn.Linear(3*hidden_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def message(self,e):\n",
    "        # constructs messages for each edge; e as given to propagate\n",
    "        return e\n",
    "\n",
    "    def aggregate(\n",
    "        self,\n",
    "        inputs: torch.Tensor,\n",
    "        index: torch.Tensor,\n",
    "        edge_index,\n",
    "        x,\n",
    "        ptr=None,\n",
    "        dim_size=None,\n",
    "    ) -> torch.Tensor:\n",
    "        # takes output from message as first argument (inputs = e), and can take any other data passed to propagate\n",
    "        # so the edge data is creating a message for source and destination nodes\n",
    "        src_message = self.aggr_module(inputs, edge_index[1], dim_size=x.size(0))\n",
    "        dst_message = self.aggr_module(inputs, edge_index[0], dim_size=x.size(0))\n",
    "        out = src_message + dst_message\n",
    "        return out\n",
    "\n",
    "    def update(self, inputs: torch.Tensor, x) -> torch.Tensor:\n",
    "        # takes the aggregated messages and the node data and updates the node data\n",
    "        x_in = torch.cat([x, inputs], dim=1)\n",
    "        out = self.node_network(x_in)\n",
    "        return out\n",
    "\n",
    "    def edge_update(self, edge_index, x, e) -> torch.Tensor:\n",
    "        x_in = torch.cat([x[edge_index[0]], x[edge_index[1]], e], dim=1)\n",
    "        out = self.edge_network(x_in)\n",
    "        return out\n",
    "\n",
    "    def forward(self, edge_index, x, e):\n",
    "        # propagate: initial call to start propagating messages, takes edge indices and any other data\n",
    "        # propagate calls message, aggreate and update functions\n",
    "        x = self.propagate(edge_index=edge_index, x=x, e=e)\n",
    "        # then we update our edge features, this calls edge_update\n",
    "        e = self.edge_updater(edge_index=edge_index, x=x, e=e)\n",
    "        return x, e\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, n_iterations=2):\n",
    "        super(InteractionNetwork, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_iterations = n_iterations\n",
    "        \n",
    "        self.node_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.edge_encoder = nn.Sequential(\n",
    "            nn.Linear(2*input_dim, hidden_dim),\n",
    "            nn.LayerNorm(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.conv = InteractionConv(hidden_dim)\n",
    "        \n",
    "        self.edge_classifier = nn.Sequential(\n",
    "            nn.Linear(3* hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "    # we take a full data batch, and make use of features we want \n",
    "    def forward(self, batch):\n",
    "        # Extract node features\n",
    "        x = torch.stack([batch.r, batch.phi, batch.z], dim=-1).to(torch.float32)\n",
    "        edge_index = batch.edge_index\n",
    "        #print(f\"x= {x}\")\n",
    "        #print(f\"edge_index= {edge_index.shape}\")\n",
    "        \n",
    "        #if \"undirected\" in self.hparams and self.hparams[\"undirected\"]:\n",
    "        #edge_index = torch.cat([edge_index, edge_index.flip(0)], dim=1)\n",
    "        #print(f\"edge_index= {edge_index.shape}\")\n",
    "\n",
    "        start, end = edge_index\n",
    "        x.requires_grad = True\n",
    "        #print(start, end)\n",
    "\n",
    "        e = self.edge_encoder(torch.cat([x[start], x[end]], dim=-1))\n",
    "        x = self.node_encoder(x)\n",
    "        #print(x)\n",
    "        #print(e)\n",
    "        # Message passing\n",
    "        for i in range(self.n_iterations):\n",
    "            x, e = self.conv(edge_index, x, e)\n",
    "            \n",
    "        #return\n",
    "        # Decode edge features\n",
    "        decoded = self.edge_classifier(torch.cat([x[start], x[end], e], dim=-1))\n",
    "        \n",
    "        #print(decoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[2718], edge_index=[2, 7649], y=[7649], leta=[2718], module_index=[2718], lx=[2718], region=[2718], lphi=[2718], cell_val=[2718], weight=[2718], lz=[2718], phi=[2718], ly=[2718], hit_id=[2718], eta=[2718], geta=[2718], r=[2718], cell_count=[2718], z=[2718], gphi=[2718], track_edges=[2, 2477], particle_id=[2477], radius=[2477], pt=[2477], nhits=[2477], config=[1], event_id=[1], num_nodes=2718, batch=[2718], truth_map=[2477], weights=[7649], ptr=[2])\n",
      "tensor([[0.2116],\n",
      "        [0.2464],\n",
      "        [0.2155],\n",
      "        ...,\n",
      "        [0.2229],\n",
      "        [0.2230],\n",
      "        [0.2267]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = InteractionNetwork(input_dim=3, hidden_dim=32, n_iterations=2)\n",
    "print(test_event)\n",
    "test_run = model(test_event)\n",
    "print(test_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "epochs = 5\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def loss_function(output, batch):\n",
    "        \"\"\"\n",
    "        Applies the loss function to the output of the model and the truth labels.\n",
    "        To balance the positive and negative contribution, simply take the means of each separately.\n",
    "        Any further fine tuning to the balance of true target, true background and fake can be handled\n",
    "        with the `weighting` config option.\n",
    "        \"\"\"\n",
    "\n",
    "        assert hasattr(batch, \"y\"), (\n",
    "            \"The batch does not have a truth label. Please ensure the batch has a `y`\"\n",
    "            \" attribute.\"\n",
    "        )\n",
    "        assert hasattr(batch, \"weights\"), (\n",
    "            \"The batch does not have a weighting label. Please ensure the batch\"\n",
    "            \" weighting is handled in preprocessing.\"\n",
    "        )\n",
    "\n",
    "        negative_mask = ((batch.y == 0) & (batch.weights != 0)) | (batch.weights < 0)\n",
    "        #print(negative_mask.shape)\n",
    "        #print(output[negative_mask].shape)\n",
    "        #print(batch.weights[negative_mask].abs().shape)\n",
    "\n",
    "        negative_loss = F.binary_cross_entropy_with_logits(\n",
    "            output[negative_mask],\n",
    "            torch.zeros_like(output[negative_mask]),\n",
    "            #weight=batch.weights[negative_mask].abs(),\n",
    "            reduction=\"sum\",\n",
    "        )\n",
    "\n",
    "        positive_mask = (batch.y == 1) & (batch.weights > 0)\n",
    "        positive_loss = F.binary_cross_entropy_with_logits(\n",
    "            output[positive_mask],\n",
    "            torch.ones_like(output[positive_mask]),\n",
    "            #weight=batch.weights[positive_mask].abs(),\n",
    "            reduction=\"sum\",\n",
    "        )\n",
    "\n",
    "        n = positive_mask.sum() + negative_mask.sum()\n",
    "        return (\n",
    "            (positive_loss + negative_loss) / n,\n",
    "            positive_loss.detach() / n,\n",
    "            negative_loss.detach() / n,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loops over our optimization code\n",
    "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "\n",
    "    for batchid, batch in enumerate(dataloader):\n",
    "\n",
    "        output = model(batch)\n",
    "        loss, pos_loss, neg_loss = loss_fn(output, batch)\n",
    "        scores = torch.sigmoid(output)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batchid % 10 == 0:\n",
    "            loss, current = loss.item(), batchid * batch_size + len(batch.event_id)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        # Clear GPU memory\n",
    "        del batch\n",
    "        torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model's performance against the test dataset\n",
    "def test_loop(dataloader, model, loss_fn, optimizer, device):\n",
    "    size = len(dataloader.dataset)\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():   \n",
    "        for batchid, batch in enumerate(dataloader):\n",
    "\n",
    "            output = model(batch)\n",
    "            loss, pos_loss, neg_loss = loss_fn(output, batch)\n",
    "            scores = torch.sigmoid(output)\n",
    "            test_loss += loss\n",
    "\n",
    "            # Clear GPU memory\n",
    "            del batch\n",
    "            torch.cuda.empty_cache()\n",
    "    test_loss /= size\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.741230  [    1/   80]\n",
      "loss: 0.641859  [   11/   80]\n",
      "loss: 0.613610  [   21/   80]\n",
      "loss: 0.616529  [   31/   80]\n",
      "loss: 0.554355  [   41/   80]\n",
      "loss: 0.585642  [   51/   80]\n",
      "loss: 0.573608  [   61/   80]\n",
      "loss: 0.600520  [   71/   80]\n",
      "Test Error: \n",
      " Avg loss: 0.567785 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.591930  [    1/   80]\n",
      "loss: 0.579573  [   11/   80]\n",
      "loss: 0.563805  [   21/   80]\n",
      "loss: 0.574940  [   31/   80]\n",
      "loss: 0.510036  [   41/   80]\n",
      "loss: 0.550159  [   51/   80]\n",
      "loss: 0.535475  [   61/   80]\n",
      "loss: 0.562351  [   71/   80]\n",
      "Test Error: \n",
      " Avg loss: 0.527509 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.546477  [    1/   80]\n",
      "loss: 0.530489  [   11/   80]\n",
      "loss: 0.501238  [   21/   80]\n",
      "loss: 0.465706  [   31/   80]\n",
      "loss: 0.404503  [   41/   80]\n",
      "loss: 0.411440  [   51/   80]\n",
      "loss: 0.395450  [   61/   80]\n",
      "loss: 0.390389  [   71/   80]\n",
      "Test Error: \n",
      " Avg loss: 0.372886 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.379105  [    1/   80]\n",
      "loss: 0.383974  [   11/   80]\n",
      "loss: 0.377675  [   21/   80]\n",
      "loss: 0.363688  [   31/   80]\n",
      "loss: 0.342778  [   41/   80]\n",
      "loss: 0.359618  [   51/   80]\n",
      "loss: 0.345597  [   61/   80]\n",
      "loss: 0.358223  [   71/   80]\n",
      "Test Error: \n",
      " Avg loss: 0.349410 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.355438  [    1/   80]\n",
      "loss: 0.357017  [   11/   80]\n",
      "loss: 0.356178  [   21/   80]\n",
      "loss: 0.345088  [   31/   80]\n",
      "loss: 0.323215  [   41/   80]\n",
      "loss: 0.343023  [   51/   80]\n",
      "loss: 0.332709  [   61/   80]\n",
      "loss: 0.341086  [   71/   80]\n",
      "Test Error: \n",
      " Avg loss: 0.334317 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "val_loss = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_loader, model, loss_function, optimizer, device)\n",
    "    val_loss.append(test_loop(val_loader, model, loss_function, optimizer, device))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for name, param in model.named_parameters():\n",
    "#    print(f\"Parameter name: {name}, Size: {param.size()}, Values: {param}\")\n",
    "\n",
    "# Assuming you have the `test_loss` variable containing the loss values for each epoch\n",
    "epochs = range(1, len(val_loss) + 1)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(epochs, val_loss, 'b', label='Test Loss')\n",
    "plt.title('Validation Loss vs Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seb_acorn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
